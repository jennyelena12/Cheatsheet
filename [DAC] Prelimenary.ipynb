{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e14f1f18a94540228d8803d6dc9debf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42a814ae8920444c98b2f266cb129aa9","IPY_MODEL_0d9591831715409f9123f24db0e6315a","IPY_MODEL_1ee8a4c73aaf4102ba04861350ec8aba"],"layout":"IPY_MODEL_ae527e9156014de4a0d28e5a090f1349"}},"42a814ae8920444c98b2f266cb129aa9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff692c12ab1d4680a2f9a1e345acd4b9","placeholder":"​","style":"IPY_MODEL_2ace7066f0c043e7bee27937106fae61","value":"tokenizer_config.json: 100%"}},"0d9591831715409f9123f24db0e6315a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15c0772b797142a3a0ef79a5a95d8f62","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df0c829abbec4042bab71491ee471dd0","value":52}},"1ee8a4c73aaf4102ba04861350ec8aba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69124d58328842d696641ae8ecdaac55","placeholder":"​","style":"IPY_MODEL_afba0770a3c446f0a131d239c6ac444e","value":" 52.0/52.0 [00:00&lt;00:00, 5.51kB/s]"}},"ae527e9156014de4a0d28e5a090f1349":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff692c12ab1d4680a2f9a1e345acd4b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ace7066f0c043e7bee27937106fae61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15c0772b797142a3a0ef79a5a95d8f62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0c829abbec4042bab71491ee471dd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69124d58328842d696641ae8ecdaac55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afba0770a3c446f0a131d239c6ac444e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da558cf372774d89a1f612296b846eea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c999824f5fc240cdae66ac1b11ef2c81","IPY_MODEL_faa352243863431691d4b1f1cda804b7","IPY_MODEL_e70ac7fcc01e4ba59b6dd926bbdb7def"],"layout":"IPY_MODEL_023b3ba4155845e9baa8a7ac163d28cf"}},"c999824f5fc240cdae66ac1b11ef2c81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f81c20f43fc421592972c2d61a6b00b","placeholder":"​","style":"IPY_MODEL_979fafa2adda458b8fc2fe8a6cf87c7e","value":"config.json: 100%"}},"faa352243863431691d4b1f1cda804b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31691adc66624642ad62ae02dfe98fd9","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3e2130b2779451f8b191be2b1f8e4df","value":579}},"e70ac7fcc01e4ba59b6dd926bbdb7def":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f9ceb7ff1a741c389bdda07d3354dfb","placeholder":"​","style":"IPY_MODEL_83b4a421909541f290e755970c6326ba","value":" 579/579 [00:00&lt;00:00, 67.7kB/s]"}},"023b3ba4155845e9baa8a7ac163d28cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f81c20f43fc421592972c2d61a6b00b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"979fafa2adda458b8fc2fe8a6cf87c7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31691adc66624642ad62ae02dfe98fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3e2130b2779451f8b191be2b1f8e4df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f9ceb7ff1a741c389bdda07d3354dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b4a421909541f290e755970c6326ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c48aa54d3ac47a7ba15735445d9596a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df0e0b8c08a84a6d81dc9220a90272aa","IPY_MODEL_880559ccaa0142db9ec2c5fac280addf","IPY_MODEL_da2f9ceb7e414221a5fc8b05e43694ac"],"layout":"IPY_MODEL_45ff61cb21a641cc92d9254c255272a7"}},"df0e0b8c08a84a6d81dc9220a90272aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a64e3761124358a2ca52f86484b952","placeholder":"​","style":"IPY_MODEL_0d75dd51c3ce41d3a2392ab82d9ce0e7","value":"spm.model: 100%"}},"880559ccaa0142db9ec2c5fac280addf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab0764097e9a491c8afefd8c4071d933","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3847cc16e09c4d93bee31bfe8af9c2eb","value":2464616}},"da2f9ceb7e414221a5fc8b05e43694ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5219e1584d14f61aedadfb544e99431","placeholder":"​","style":"IPY_MODEL_2bbb81ac424d48ea827b8920e6c3b8c4","value":" 2.46M/2.46M [00:00&lt;00:00, 4.36MB/s]"}},"45ff61cb21a641cc92d9254c255272a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a64e3761124358a2ca52f86484b952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d75dd51c3ce41d3a2392ab82d9ce0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab0764097e9a491c8afefd8c4071d933":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3847cc16e09c4d93bee31bfe8af9c2eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5219e1584d14f61aedadfb544e99431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bbb81ac424d48ea827b8920e6c3b8c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"338de116b5014b2ab0fe83bed0a61207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_225494279a764773981c585f697d9d68","IPY_MODEL_d8de99bba5cd444aa7af540fdc1422cc","IPY_MODEL_0e637e16ba81418f82b84b023cb25b1f"],"layout":"IPY_MODEL_a228d0d7f88347e397669cdbae51a6bf"}},"225494279a764773981c585f697d9d68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36f68eeb25d242c2a6b5579162960516","placeholder":"​","style":"IPY_MODEL_0a556f619bef4ca7a39dab6ac28a97d5","value":"pytorch_model.bin: 100%"}},"d8de99bba5cd444aa7af540fdc1422cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7496ae8ddfe48b1b78156fb878ae4ca","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_353e9aa556554ff9b5fd43ea67097160","value":371146213}},"0e637e16ba81418f82b84b023cb25b1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_500d29c6ba7d4702ba19dd714fa9ec98","placeholder":"​","style":"IPY_MODEL_6e02e0cc2720449db008e9fc80dd2484","value":" 371M/371M [00:05&lt;00:00, 90.8MB/s]"}},"a228d0d7f88347e397669cdbae51a6bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f68eeb25d242c2a6b5579162960516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a556f619bef4ca7a39dab6ac28a97d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7496ae8ddfe48b1b78156fb878ae4ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353e9aa556554ff9b5fd43ea67097160":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"500d29c6ba7d4702ba19dd714fa9ec98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e02e0cc2720449db008e9fc80dd2484":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dc8b7b4384448d79e1ccb6c48ead079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d54e161e96649da8bb0eecb258ec372","IPY_MODEL_219d5f0cc4db4c0597ca11bb6811c966","IPY_MODEL_bafe8d9b7c6d43ada969318fb980c929"],"layout":"IPY_MODEL_0bf8b62d3226485a89b8ea3eb78e4bf2"}},"3d54e161e96649da8bb0eecb258ec372":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06734c85a924c5a9849b55f77ee7fe4","placeholder":"​","style":"IPY_MODEL_eaf3f3f12f5c4aac946f473a9aa69155","value":"model.safetensors: 100%"}},"219d5f0cc4db4c0597ca11bb6811c966":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca9757fdb6754dddbec5cb4359e6048d","max":371101258,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ed0b578074a44b8a05d4ddf20bddd02","value":371101258}},"bafe8d9b7c6d43ada969318fb980c929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90117565db464bee9cffec398eba9335","placeholder":"​","style":"IPY_MODEL_a2ff30621a714384bc42dd2e507623b6","value":" 371M/371M [00:06&lt;00:00, 48.6MB/s]"}},"0bf8b62d3226485a89b8ea3eb78e4bf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06734c85a924c5a9849b55f77ee7fe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf3f3f12f5c4aac946f473a9aa69155":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca9757fdb6754dddbec5cb4359e6048d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ed0b578074a44b8a05d4ddf20bddd02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90117565db464bee9cffec398eba9335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ff30621a714384bc42dd2e507623b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["DAC ITS - 2025 viva LnT"],"metadata":{"id":"jVR6qTQhY9NY"}},{"cell_type":"code","source":["!unzip /content/data-analysis-competition-2025.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aam6xfxDTOt","outputId":"06e67b72-161b-4654-b902-d24b7bbb8a58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/data-analysis-competition-2025.zip\n","  inflating: Test/claude.csv         \n","  inflating: Test/deepseek.csv       \n","  inflating: Test/gemini.csv         \n","  inflating: Test/gpt.csv            \n","  inflating: Test/grok.csv           \n","  inflating: Test/perplexity.csv     \n","  inflating: Train/claude.csv        \n","  inflating: Train/deepseek.csv      \n","  inflating: Train/gemini.csv        \n","  inflating: Train/gpt.csv           \n","  inflating: Train/grok.csv          \n","  inflating: Train/perplexity.csv    \n","  inflating: sample_submission.csv   \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e14f1f18a94540228d8803d6dc9debf4","42a814ae8920444c98b2f266cb129aa9","0d9591831715409f9123f24db0e6315a","1ee8a4c73aaf4102ba04861350ec8aba","ae527e9156014de4a0d28e5a090f1349","ff692c12ab1d4680a2f9a1e345acd4b9","2ace7066f0c043e7bee27937106fae61","15c0772b797142a3a0ef79a5a95d8f62","df0c829abbec4042bab71491ee471dd0","69124d58328842d696641ae8ecdaac55","afba0770a3c446f0a131d239c6ac444e","da558cf372774d89a1f612296b846eea","c999824f5fc240cdae66ac1b11ef2c81","faa352243863431691d4b1f1cda804b7","e70ac7fcc01e4ba59b6dd926bbdb7def","023b3ba4155845e9baa8a7ac163d28cf","7f81c20f43fc421592972c2d61a6b00b","979fafa2adda458b8fc2fe8a6cf87c7e","31691adc66624642ad62ae02dfe98fd9","a3e2130b2779451f8b191be2b1f8e4df","0f9ceb7ff1a741c389bdda07d3354dfb","83b4a421909541f290e755970c6326ba","9c48aa54d3ac47a7ba15735445d9596a","df0e0b8c08a84a6d81dc9220a90272aa","880559ccaa0142db9ec2c5fac280addf","da2f9ceb7e414221a5fc8b05e43694ac","45ff61cb21a641cc92d9254c255272a7","79a64e3761124358a2ca52f86484b952","0d75dd51c3ce41d3a2392ab82d9ce0e7","ab0764097e9a491c8afefd8c4071d933","3847cc16e09c4d93bee31bfe8af9c2eb","a5219e1584d14f61aedadfb544e99431","2bbb81ac424d48ea827b8920e6c3b8c4","338de116b5014b2ab0fe83bed0a61207","225494279a764773981c585f697d9d68","d8de99bba5cd444aa7af540fdc1422cc","0e637e16ba81418f82b84b023cb25b1f","a228d0d7f88347e397669cdbae51a6bf","36f68eeb25d242c2a6b5579162960516","0a556f619bef4ca7a39dab6ac28a97d5","c7496ae8ddfe48b1b78156fb878ae4ca","353e9aa556554ff9b5fd43ea67097160","500d29c6ba7d4702ba19dd714fa9ec98","6e02e0cc2720449db008e9fc80dd2484","2dc8b7b4384448d79e1ccb6c48ead079","3d54e161e96649da8bb0eecb258ec372","219d5f0cc4db4c0597ca11bb6811c966","bafe8d9b7c6d43ada969318fb980c929","0bf8b62d3226485a89b8ea3eb78e4bf2","d06734c85a924c5a9849b55f77ee7fe4","eaf3f3f12f5c4aac946f473a9aa69155","ca9757fdb6754dddbec5cb4359e6048d","7ed0b578074a44b8a05d4ddf20bddd02","90117565db464bee9cffec398eba9335","a2ff30621a714384bc42dd2e507623b6"]},"id":"L6WZUEhoBXc5","outputId":"11329589-211e-407f-93d9-af966ca6c206"},"outputs":[{"output_type":"stream","name":"stdout","text":["Counts after augmentation: {2: 107771, 0: 17520, 1: 17205}\n","Initializing tokenizer... microsoft/deberta-v3-base\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1593786007.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  aug_df = aug_df.groupby(\"label\", group_keys=False).apply(lambda g: g.sample(frac=frac, random_state=RND)).reset_index(drop=True)\n","/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14f1f18a94540228d8803d6dc9debf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da558cf372774d89a1f612296b846eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c48aa54d3ac47a7ba15735445d9596a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Class weights: [2.711, 2.7609, 0.4407]\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1593786007.py:188: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MaxTrainer.__init__`. Use `processing_class` instead.\n","  super().__init__(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"338de116b5014b2ab0fe83bed0a61207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc8b7b4384448d79e1ccb6c48ead079"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Running quick HPO-validation pass to catch OOMs and check metrics\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5625/5625 11:54, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>F1 0</th>\n","      <th>F1 1</th>\n","      <th>F1 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.782400</td>\n","      <td>0.809611</td>\n","      <td>0.710097</td>\n","      <td>0.729236</td>\n","      <td>0.467327</td>\n","      <td>0.933727</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7453    0.7138    0.7292       615\n","   1_neu/mix     0.5813    0.3907    0.4673       604\n","       2_pos     0.9076    0.9614    0.9337      3781\n","\n","    accuracy                         0.8620      5000\n","   macro avg     0.7447    0.6886    0.7101      5000\n","weighted avg     0.8482    0.8620    0.8522      5000\n","\n","Per-class F1 (0,1,2): [0.7292, 0.4673, 0.9337]\n","Macro F1: 0.7101\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 439   74  102]\n"," [ 100  236  268]\n"," [  50   96 3635]]\n","====================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 00:10]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7453    0.7138    0.7292       615\n","   1_neu/mix     0.5813    0.3907    0.4673       604\n","       2_pos     0.9076    0.9614    0.9337      3781\n","\n","    accuracy                         0.8620      5000\n","   macro avg     0.7447    0.6886    0.7101      5000\n","weighted avg     0.8482    0.8620    0.8522      5000\n","\n","Per-class F1 (0,1,2): [0.7292, 0.4673, 0.9337]\n","Macro F1: 0.7101\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 439   74  102]\n"," [ 100  236  268]\n"," [  50   96 3635]]\n","====================================\n","\n","HPO eval: {'eval_loss': 0.8096112012863159, 'eval_macro_f1': 0.7100966052478, 'eval_f1_0': 0.729235880398671, 'eval_f1_1': 0.46732673267326735, 'eval_f1_2': 0.9337272026714616, 'eval_runtime': 11.0909, 'eval_samples_per_second': 450.818, 'eval_steps_per_second': 28.221, 'epoch': 1.0}\n","Starting final training with gradient checkpointing enabled (safer memory use).\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1593786007.py:188: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MaxTrainer.__init__`. Use `processing_class` instead.\n","  super().__init__(*args, **kwargs)\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final training error: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time o\n","Retrying final training WITHOUT gradient checkpointing (workaround).\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='11250' max='11250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11250/11250 23:42, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>F1 0</th>\n","      <th>F1 1</th>\n","      <th>F1 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.731800</td>\n","      <td>0.779966</td>\n","      <td>0.679042</td>\n","      <td>0.726817</td>\n","      <td>0.418478</td>\n","      <td>0.891829</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.675100</td>\n","      <td>0.883140</td>\n","      <td>0.722113</td>\n","      <td>0.741480</td>\n","      <td>0.490821</td>\n","      <td>0.934038</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7474    0.7073    0.7268       615\n","   1_neu/mix     0.3548    0.5099    0.4185       604\n","       2_pos     0.9208    0.8646    0.8918      3781\n","\n","    accuracy                         0.8024      5000\n","   macro avg     0.6744    0.6939    0.6790      5000\n","weighted avg     0.8311    0.8024    0.8144      5000\n","\n","Per-class F1 (0,1,2): [0.7268, 0.4185, 0.8918]\n","Macro F1: 0.679\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 435   91   89]\n"," [ 104  308  192]\n"," [  43  469 3269]]\n","====================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7585    0.7252    0.7415       615\n","   1_neu/mix     0.5893    0.4205    0.4908       604\n","       2_pos     0.9106    0.9587    0.9340      3781\n","\n","    accuracy                         0.8650      5000\n","   macro avg     0.7528    0.7015    0.7221      5000\n","weighted avg     0.8531    0.8650    0.8568      5000\n","\n","Per-class F1 (0,1,2): [0.7415, 0.4908, 0.934]\n","Macro F1: 0.7221\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 446   68  101]\n"," [  95  254  255]\n"," [  47  109 3625]]\n","====================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7585    0.7252    0.7415       615\n","   1_neu/mix     0.5893    0.4205    0.4908       604\n","       2_pos     0.9106    0.9587    0.9340      3781\n","\n","    accuracy                         0.8650      5000\n","   macro avg     0.7528    0.7015    0.7221      5000\n","weighted avg     0.8531    0.8650    0.8568      5000\n","\n","Per-class F1 (0,1,2): [0.7415, 0.4908, 0.934]\n","Macro F1: 0.7221\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 446   68  101]\n"," [  95  254  255]\n"," [  47  109 3625]]\n","====================================\n","\n","Final eval: {'eval_loss': 0.8831400275230408, 'eval_macro_f1': 0.7221128364855595, 'eval_f1_0': 0.741479634247714, 'eval_f1_1': 0.49082125603864735, 'eval_f1_2': 0.9340376191703169, 'eval_runtime': 10.972, 'eval_samples_per_second': 455.706, 'eval_steps_per_second': 28.527, 'epoch': 2.0}\n","Saved per-model prediction CSVs:\n"," - claude -> /content/predictions_per_model_max_opt/claude_preds.csv\n"," - deepseek -> /content/predictions_per_model_max_opt/deepseek_preds.csv\n"," - gemini -> /content/predictions_per_model_max_opt/gemini_preds.csv\n"," - gpt -> /content/predictions_per_model_max_opt/gpt_preds.csv\n"," - grok -> /content/predictions_per_model_max_opt/grok_preds.csv\n"," - perplexity -> /content/predictions_per_model_max_opt/perplexity_preds.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","===== Evaluation report (epoch) =====\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7585    0.7252    0.7415       615\n","   1_neu/mix     0.5893    0.4205    0.4908       604\n","       2_pos     0.9106    0.9587    0.9340      3781\n","\n","    accuracy                         0.8650      5000\n","   macro avg     0.7528    0.7015    0.7221      5000\n","weighted avg     0.8531    0.8650    0.8568      5000\n","\n","Per-class F1 (0,1,2): [0.7415, 0.4908, 0.934]\n","Macro F1: 0.7221\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 446   68  101]\n"," [  95  254  255]\n"," [  47  109 3625]]\n","====================================\n","\n","\n","FINAL Validation report:\n","              precision    recall  f1-score   support\n","\n","       0_neg     0.7585    0.7252    0.7415       615\n","   1_neu/mix     0.5893    0.4205    0.4908       604\n","       2_pos     0.9106    0.9587    0.9340      3781\n","\n","    accuracy                         0.8650      5000\n","   macro avg     0.7528    0.7015    0.7221      5000\n","weighted avg     0.8531    0.8650    0.8568      5000\n","\n","Macro F1: 0.7221128364855595\n","3x3 Confusion matrix (rows=true, cols=pred):\n","[[ 446   68  101]\n"," [  95  254  255]\n"," [  47  109 3625]]\n"]}],"source":["import os, glob, re, random, gc\n","from pathlib import Path\n","import numpy as np, pandas as pd\n","import torch, torch.nn as nn, torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n","                          TrainingArguments, Trainer, DataCollatorWithPadding,\n","                          EarlyStoppingCallback)\n","\n","# Config\n","MODEL_NAME = \"microsoft/deberta-v3-base\"\n","OUT_DIR = \"/content/deberta_max_t4_opt\"\n","PRED_DIR = \"/content/predictions_per_model_max_opt\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","os.makedirs(PRED_DIR, exist_ok=True)\n","TRAIN_GLOBS = [\"/content/Train/*.csv\"]\n","TEST_GLOBS  = [\"/content/Test/*.csv\"]\n","MAX_LEN = 128            # 160 to 128\n","RND = 42\n","random.seed(RND); np.random.seed(RND); torch.manual_seed(RND)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.backends.cudnn.benchmark = True\n","\n","def find_csvs(globs):\n","    p=[]\n","    for g in globs:\n","        p += glob.glob(g)\n","    return sorted([x for x in p if x.lower().endswith(\".csv\") and \"sample\" not in Path(x).stem.lower()])\n","\n","def detect_text_col(df):\n","    for c in df.columns:\n","        if c.lower() in (\"comment\",\"text\",\"review\",\"body\",\"content\",\"message\"):\n","            return c\n","    obj = [c for c in df.columns if df[c].dtype==object]\n","    return obj[0] if obj else df.columns[0]\n","\n","def detect_label_col(df):\n","    for c in df.columns:\n","        if c.lower() in (\"sentiment\",\"label\",\"target\"):\n","            return c\n","    for c in df.columns:\n","        if np.issubdtype(df[c].dtype, np.integer):\n","            return c\n","    raise ValueError(\"No label column found\")\n","\n","def detect_id_col(df):\n","    for c in df.columns:\n","        if c.lower() in (\"commentid\",\"id\",\"comment_id\",\"comment id\"):\n","            return c\n","    return None\n","\n","# Load csv\n","train_paths = find_csvs(TRAIN_GLOBS)\n","if len(train_paths)==0:\n","    raise FileNotFoundError(\"No train CSVs found\")\n","dfs=[]\n","for p in train_paths:\n","    df = pd.read_csv(p)\n","    tcol = detect_text_col(df)\n","    lcol = detect_label_col(df)\n","    df = df[[tcol, lcol]].rename(columns={tcol:\"text\", lcol:\"label\"})\n","    dfs.append(df)\n","all_train = pd.concat(dfs, ignore_index=True).dropna(subset=[\"text\"]).reset_index(drop=True)\n","all_train[\"text\"] = all_train[\"text\"].astype(str)\n","all_train[\"label\"] = all_train[\"label\"].astype(int)\n","\n","_url_re = re.compile(r\"https?://\\S+|www\\.\\S+\")\n","_mention_re = re.compile(r\"@\\w+\")\n","_nonprint_re = re.compile(r\"[\\r\\n\\t]\")\n","_multi_space = re.compile(r\"\\s+\")\n","_repeat_punct = re.compile(r\"([!?\\.]){2,}\")\n","\n","def clean_text(s):\n","    s = s or \"\"\n","    s = _url_re.sub(\" \", s)\n","    s = _mention_re.sub(\" \", s)\n","    s = _nonprint_re.sub(\" \", s)\n","    s = _repeat_punct.sub(r\"\\1\", s)\n","    s = _multi_space.sub(\" \", s)\n","    return s.strip()\n","\n","all_train[\"text\"] = all_train[\"text\"].map(clean_text)\n","\n","df0 = all_train[all_train[\"label\"]==0]\n","df1 = all_train[all_train[\"label\"]==1]\n","df2 = all_train[all_train[\"label\"]==2]\n","\n","def synth_mixed(n):\n","    out=[]\n","    if len(df0)==0 or len(df2)==0:\n","        return pd.DataFrame([], columns=all_train.columns)\n","    for _ in range(n):\n","        a = df2.sample(1).iloc[0][\"text\"]\n","        b = df0.sample(1).iloc[0][\"text\"]\n","        txt = (a + \" // \" + b) if random.random()<0.5 else (b + \" // \" + a)\n","        out.append({\"text\": txt, \"label\": 1})\n","    return pd.DataFrame(out)\n","\n","n_synth = min(1500, max(100, int(0.025 * len(all_train)))) # Fewer synthetic\n","synth_df = synth_mixed(n_synth)\n","\n","target_neutral = int(0.12 * len(all_train))\n","if len(df1) < target_neutral:\n","    need = target_neutral - len(df1)\n","    ups = df1.sample(need, replace=True, random_state=RND) if len(df1)>0 else synth_df.sample(need, replace=True, random_state=RND)\n","    df1_aug = pd.concat([df1, ups], ignore_index=True)\n","else:\n","    df1_aug = df1\n","\n","aug_df = pd.concat([df0, df1_aug, df2, synth_df], ignore_index=True).sample(frac=1.0, random_state=RND).reset_index(drop=True)\n","print(\"Counts after augmentation:\", aug_df[\"label\"].value_counts().to_dict())\n","\n","MAX_TRAIN = 50000 # 65000 to 50000\n","if len(aug_df) > MAX_TRAIN:\n","    frac = MAX_TRAIN / len(aug_df)\n","    aug_df = aug_df.groupby(\"label\", group_keys=False).apply(lambda g: g.sample(frac=frac, random_state=RND)).reset_index(drop=True)\n","\n","train_df, val_df = train_test_split(aug_df, test_size=0.10, stratify=aug_df[\"label\"], random_state=RND)\n","train_df = train_df.reset_index(drop=True); val_df = val_df.reset_index(drop=True)\n","\n","print(\"Initializing tokenizer...\", MODEL_NAME)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","\n","def tokenize_texts(texts):\n","    return tokenizer(texts, truncation=True, padding=False, max_length=MAX_LEN) # padding=False saves compute & memory\n","\n","train_enc = tokenize_texts(train_df[\"text\"].tolist())\n","val_enc   = tokenize_texts(val_df[\"text\"].tolist())\n","\n","class TorchDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","    def __getitem__(self, idx):\n","        item = {k: self.encodings[k][idx] for k in self.encodings}\n","        # Let DataCollator convert to tensors and pad\n","        if self.labels is not None:\n","            item[\"labels\"] = int(self.labels[idx])\n","        return item\n","\n","train_dataset = TorchDataset(train_enc, train_df[\"label\"].tolist())\n","val_dataset = TorchDataset(val_enc, val_df[\"label\"].tolist())\n","\n","train_labels = np.array(train_df[\"label\"].tolist())\n","num_labels = int(train_labels.max()) + 1\n","cw = compute_class_weight(class_weight=\"balanced\", classes=np.arange(num_labels), y=train_labels)\n","cw = np.maximum(cw, 1e-6)\n","print(\"Class weights:\", cw.round(4).tolist())\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n","        super().__init__()\n","        self.gamma = gamma; self.reduction = reduction\n","        self.alpha = torch.tensor(alpha, dtype=torch.float) if alpha is not None else None\n","    def forward(self, logits, targets):\n","        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n","        p_t = torch.exp(-ce)\n","        loss = ((1 - p_t) ** self.gamma) * ce\n","        if self.alpha is not None:\n","            at = self.alpha.to(loss.device)[targets]\n","            loss = at * loss\n","        return loss.mean() if self.reduction==\"mean\" else loss.sum()\n","\n","class MaxTrainer(Trainer):\n","    def __init__(self, use_focal=False, focal_gamma=2.0, focal_alpha=None, use_weighted_ce=False, weight_tensor=None, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.use_focal = use_focal\n","        self.focal_gamma = focal_gamma\n","        self.focal_alpha = focal_alpha\n","        self.use_weighted_ce = use_weighted_ce\n","        self.weight_tensor = torch.tensor(weight_tensor, dtype=torch.float) if weight_tensor is not None else None\n","        if self.use_focal:\n","            self.focal = FocalLoss(gamma=self.focal_gamma, alpha=self.focal_alpha)\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.pop(\"labels\", None)\n","        if labels is None:\n","            raise KeyError(\"No labels found\")\n","        if isinstance(labels, torch.Tensor):\n","            labels = labels.to(model.device)\n","        else:\n","            labels = torch.tensor(labels, device=model.device)\n","        if labels.dtype != torch.long:\n","            labels = labels.long()\n","        outputs = model(**{k:(v.to(model.device) if isinstance(v, torch.Tensor) else v) for k,v in inputs.items()})\n","        logits = outputs.logits\n","        if self.use_focal:\n","            loss = self.focal(logits, labels)\n","        else:\n","            if self.use_weighted_ce and (self.weight_tensor is not None):\n","                wt = self.weight_tensor.to(logits.device)\n","                loss = F.cross_entropy(logits, labels, weight=wt)\n","            else:\n","                loss = F.cross_entropy(logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    macro = float(f1_score(labels, preds, average=\"macro\"))\n","    per_class = f1_score(labels, preds, average=None, labels=[0,1,2])\n","    try:\n","        crep = classification_report(labels, preds, digits=4, target_names=[\"0_neg\",\"1_neu/mix\",\"2_pos\"])\n","    except Exception:\n","        crep = str(classification_report(labels, preds, digits=4))\n","    cm = confusion_matrix(labels, preds, labels=[0,1,2])\n","    print(\"\\n===== Evaluation report (epoch) =====\")\n","    print(crep)\n","    print(\"Per-class F1 (0,1,2):\", np.round(per_class,4).tolist())\n","    print(\"Macro F1:\", round(macro,4))\n","    print(\"3x3 Confusion matrix (rows=true, cols=pred):\")\n","    print(cm)\n","    print(\"====================================\\n\")\n","    return {\"macro_f1\": macro, \"f1_0\": float(per_class[0]), \"f1_1\": float(per_class[1]), \"f1_2\": float(per_class[2])}\n","\n","def safe_model_init(enable_checkpointing=False):\n","    m = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels, ignore_mismatched_sizes=True, low_cpu_mem_usage=True)\n","    if enable_checkpointing:\n","        try:\n","            m.gradient_checkpointing_enable()\n","        except Exception:\n","            pass\n","    return m\n","\n","preferred_batch = 8\n","fallback_batch = 4\n","effective_epochs = 2\n","\n","best_cfg = {\"learning_rate\":2e-5, \"per_device_train_batch_size\":preferred_batch, \"gradient_accumulation_steps\":1}\n","per_device_train_batch_size = best_cfg[\"per_device_train_batch_size\"]\n","per_device_eval_batch_size = max(16, per_device_train_batch_size*2)\n","\n","hpo_args = TrainingArguments(\n","    output_dir=os.path.join(OUT_DIR, \"hpo\"),\n","    num_train_epochs=1,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_accumulation_steps=best_cfg[\"gradient_accumulation_steps\"],\n","    learning_rate=best_cfg[\"learning_rate\"],\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"no\",\n","    logging_strategy=\"steps\",\n","    logging_steps=200,\n","    weight_decay=0.01,\n","    fp16=True if DEVICE==\"cuda\" else False,\n","    dataloader_num_workers=4,\n","    report_to=\"none\"\n",")\n","\n","data_collator = DataCollatorWithPadding(tokenizer)\n","hpo_trainer = MaxTrainer(\n","    model_init=lambda: safe_model_init(enable_checkpointing=False),\n","    args=hpo_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    use_focal=False,\n","    use_weighted_ce=True,\n","    weight_tensor=cw.tolist()\n",")\n","\n","print(\"Running quick HPO-validation pass to catch OOMs and check metrics\")\n","try:\n","    hpo_trainer.train()\n","    hpo_res = hpo_trainer.evaluate()\n","    print(\"HPO eval:\", hpo_res)\n","except RuntimeError as e:\n","    msg = str(e)\n","    print(\"HPO error:\", msg[:300])\n","    if \"out of memory\" in msg.lower():\n","        print(\"OOM during HPO: lowering batch size and retrying with batch\", fallback_batch)\n","        torch.cuda.empty_cache(); gc.collect()\n","        best_cfg[\"per_device_train_batch_size\"] = fallback_batch\n","        per_device_train_batch_size = fallback_batch\n","        per_device_eval_batch_size = max(8, per_device_train_batch_size*2)\n","        hpo_args = hpo_args.__class__(**{k:getattr(hpo_args,k) for k in hpo_args.to_sanitized_dict()})\n","        hpo_args.per_device_train_batch_size = per_device_train_batch_size\n","        hpo_args.per_device_eval_batch_size = per_device_eval_batch_size\n","        hpo_trainer = MaxTrainer(\n","            model_init=lambda: safe_model_init(enable_checkpointing=False),\n","            args=hpo_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=val_dataset,\n","            tokenizer=tokenizer,\n","            data_collator=data_collator,\n","            compute_metrics=compute_metrics,\n","            use_focal=False,\n","            use_weighted_ce=True,\n","            weight_tensor=cw.tolist()\n","        )\n","        hpo_trainer.train(); hpo_res = hpo_trainer.evaluate(); print(\"HPO eval (retry):\", hpo_res)\n","\n","del hpo_trainer\n","torch.cuda.empty_cache(); gc.collect()\n","\n","final_args = TrainingArguments(\n","    output_dir=OUT_DIR,\n","    num_train_epochs=effective_epochs,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_accumulation_steps=best_cfg[\"gradient_accumulation_steps\"],\n","    learning_rate=best_cfg[\"learning_rate\"],\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_strategy=\"steps\",\n","    logging_steps=200,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"macro_f1\",\n","    greater_is_better=True,\n","    fp16=True if DEVICE==\"cuda\" else False,\n","    dataloader_num_workers=4,\n","    report_to=\"none\"\n",")\n","\n","def run_final(enable_checkpointing):\n","    trainer = MaxTrainer(\n","        model_init=lambda: safe_model_init(enable_checkpointing=enable_checkpointing),\n","        args=final_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","        use_focal=False,\n","        use_weighted_ce=True,\n","        weight_tensor=cw.tolist()\n","    )\n","    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n","    trainer.train()\n","    res = trainer.evaluate()\n","    return trainer, res\n","\n","print(\"Starting final training with gradient checkpointing enabled (safer memory use).\")\n","try:\n","    final_trainer, final_res = run_final(enable_checkpointing=True)\n","except RuntimeError as e:\n","    msg = str(e)\n","    print(\"Final training error:\", msg[:300])\n","    if \"backward through the graph a second time\" in msg or \"retain_graph\" in msg:\n","        print(\"Retrying final training WITHOUT gradient checkpointing (workaround).\")\n","        torch.cuda.empty_cache(); gc.collect()\n","        final_trainer, final_res = run_final(enable_checkpointing=False)\n","    elif \"out of memory\" in msg.lower():\n","        print(\"OOM on final training: lowering batch size and retrying.\")\n","        torch.cuda.empty_cache(); gc.collect()\n","        final_args.per_device_train_batch_size = fallback_batch\n","        final_args.per_device_eval_batch_size = max(8, fallback_batch*2)\n","        final_trainer, final_res = run_final(enable_checkpointing=False)\n","    else:\n","        raise\n","\n","print(\"Final eval:\", final_res)\n","final_trainer.save_model(OUT_DIR)\n","tokenizer.save_pretrained(OUT_DIR)\n","test_paths = find_csvs(TEST_GLOBS)\n","if len(test_paths) == 0:\n","    print(\"No test CSVs found; skipping prediction.\")\n","else:\n","    def predict_on_file(path, batch=64):\n","        df = pd.read_csv(path)\n","        tcol = detect_text_col(df)\n","        idcol = detect_id_col(df)\n","        texts = df[tcol].fillna(\"\").astype(str).tolist()\n","        ids = df[idcol].astype(str).tolist() if idcol else [f\"{Path(path).stem}_{i+1}\" for i in range(len(texts))]\n","        preds = []\n","        for start in range(0, len(texts), 512):\n","            chunk = texts[start:start+512]\n","            enc = tokenizer(chunk, truncation=True, padding=True, max_length=MAX_LEN, return_tensors=\"pt\")\n","            input_ids = enc[\"input_ids\"].to(final_trainer.model.device)\n","            attention_mask = enc[\"attention_mask\"].to(final_trainer.model.device)\n","            with torch.no_grad():\n","                logits = final_trainer.model(input_ids=input_ids, attention_mask=attention_mask).logits\n","                batch_preds = logits.detach().cpu().numpy().argmax(axis=-1).tolist()\n","            preds.extend(batch_preds)\n","        return pd.DataFrame({\"CommentId\": ids, \"Sentiment\": preds})\n","\n","    saved = {}\n","    for p in test_paths:\n","        stem = Path(p).stem.lower()\n","        out_df = predict_on_file(p, batch=64)\n","        out_path = os.path.join(PRED_DIR, f\"{stem}_preds.csv\")\n","        out_df.to_csv(out_path, index=False)\n","        saved[stem] = out_path\n","\n","    print(\"Saved per-model prediction CSVs:\")\n","    for k,v in saved.items():\n","        print(\" -\", k, \"->\", v)\n","\n","preds = final_trainer.predict(val_dataset)\n","y_pred = preds.predictions.argmax(axis=-1)\n","y_true = np.array(val_df[\"label\"].tolist())\n","print(\"\\nFINAL Validation report:\")\n","print(classification_report(y_true, y_pred, digits=4, target_names=[\"0_neg\",\"1_neu/mix\",\"2_pos\"]))\n","print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n","print(\"3x3 Confusion matrix (rows=true, cols=pred):\")\n","print(confusion_matrix(y_true, y_pred, labels=[0,1,2]))"]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_paths = [\n","    \"/content/predictions_per_model_max_opt/gpt_preds.csv\",\n","    \"/content/predictions_per_model_max_opt/claude_preds.csv\",\n","    \"/content/predictions_per_model_max_opt/deepseek_preds.csv\",\n","    \"/content/predictions_per_model_max_opt/gemini_preds.csv\",\n","    \"/content/predictions_per_model_max_opt/grok_preds.csv\",\n","    \"/content/predictions_per_model_max_opt/perplexity_preds.csv\",\n","]\n","\n","processed_dfs = []\n","\n","for file_path in file_paths:\n","    df = pd.read_csv(file_path)\n","    model_name = file_path.split('/')[-1].split('_')[0]\n","    df['CommentId'] = model_name + '_' + df['CommentId'].astype(str)\n","    processed_dfs.append(df)\n","\n","combined_df = pd.concat(processed_dfs).reset_index(drop=True)\n","model_order = [\"gpt\", \"claude\", \"deepseek\", \"gemini\", \"grok\", \"perplexity\"]\n","combined_df['model_name'] = combined_df['CommentId'].apply(lambda x: x.split('_')[0])\n","combined_df['numeric_id'] = combined_df['CommentId'].apply(lambda x: int(x.split('_')[1]))\n","combined_df['model_name'] = pd.Categorical(combined_df['model_name'], categories=model_order, ordered=True)\n","combined_df = combined_df.sort_values(by=['model_name', 'numeric_id']).reset_index(drop=True)\n","combined_df = combined_df.drop(columns=['model_name', 'numeric_id'])\n","combined_df.to_csv(\"DebertaOptimusPrime.csv\", index=False)"],"metadata":{"id":"o7Am2ppDOWsM"},"execution_count":null,"outputs":[]}]}